
# [Tutorial] Descriptieve statistieken

```{r include=FALSE}
library(tufte)
library(dplyr)
library(ggplot2)
library(pander)
knitr::opts_current$set(cache =T, warning = F)
```
```{r echo = F} 
knitr::opts_chunk$set(out.width = "100%",
                      fig.width = 6, fig.asp = 0.6, tidy='styler',
                      cache = T,
                      echo = T)
```



## Voor je begint

Voordat je aan deze tutorial begint, moet je eerst de pakketten `dplyr`, `tidyr`, `ggcorrplot`, en `ggplot2` geïnstalleerd hebben, __als je dat nog niet gedaan hebt__. Deze kunt u laden met de `library` functie. Als je sommige nog moet installeren, gebruik dan eerst `install.packages`.

```{r warning = F, message = F}
library(dplyr)
library(tidyr)
library(ggplot2)
```

Daarnaast wil je misschien ook de volgende packages gebruiken. Ze zullen nuttig blijken op een bepaald punt in deze tutorial, maar zijn niet strikt noodzakelijk.

```{r warning = F, message = F}
library(pander)
library(forcats)
```



```{r echo = F}
data(mpg)
mpg %>% 
	mutate(manufacturer = factor(manufacturer),
		   model = factor(model),
		   cyl = ordered(cyl),
		   trans = factor(trans),
		   drv = factor(drv),
		   fl = factor(fl),
		   class = factor(class)) -> mpg

saveRDS(as.data.frame(mpg), "mpg.RDS")
```

Deze tutorial  maakt gebruik van de `mpg` dataset, die informatie bevat over 234 verschillende auto's. Het `mpg.RDS` bestand wordt met deze tutorial meegeleverd. 

```{r}
mpg <- readRDS("mpg.RDS")
```

De dataset bevat de volgende variabelen: [^1]

Variabele | Beschrijving
--------------------------|-------------------------------------------
manufacturer | De fabrikant
model| De naam van het model
displ | Motorinhoud, in liters
year | bouwjaar
cyl | Aantal cilinders
trans | Type transmissie (_koppeling_)
drv | f = voorwielaandrijving, r = achterwielaandrijving, 4 = 4wd
cty | Aantal mijl per gallon brandstof in stadsomgeving
hwy | Aantal mijl per gallon brandstof op snelweg
fl | Brandstoftype (c,d,e,p,r)
class | Type auto (2seater, compact, midsize, minivan, pickup, subcompact, suv)


[^1]: Hoewel het bepaalde analyses interessanter maakt als je bekend bent met de betekenis van de verschillende variabelen, is geen specifieke kennis van auto's vereist om deze tutorial te voltooien.

## Introductie 

Het doel van deze tutorial is om zowel univariate als bivariate analyses uit te voeren met het `dplyr` package. Verder zullen in een beperkt aantal gevallen de `tidyr` en `ggcorrplot` packages. worden gebruikt voor extra ondersteuning. 

De univariate analyse wordt uitgevoerd voor zowel categorische als continue variabelen. De bivariate analyse wordt uitgevoerd voor elk van de volgende paren: continu-categorisch, continu-continu en categorisch-categorisch. Naast een _numerieke_ analyse met behulp van functies uit de eerder genoemde pakketten, zullen de analyses vergezeld gaan van passende grafieken gemaakt met `ggplot2`. Een basiskennis van `ggplot2` is vereist. 

De tutorial is als volgt opgebouwd:

* Enkele algemene, nuttige dplyr functies 
* Univariate analyse van een continue variabele
* Bivariate analyse van een continue variabele vs. een categorische variabele
* Univariate analyse van een categorische variabele
* Bivariate analyse van een continue variabele vs. een andere continue variabele
* Bivariate analyse van een categorische variabele vs. een andere categorische variabele

## Nuttige dplyr functies

Voordat we overgaan tot het analyseren van onze dataset, zijn er een paar handige hulpfuncties in dplyr die we kunnen gebruiken om onze gegevens te verwerken en te analyseren. De eerste is `as_tibble`.

### Tibbles

Gegeven een data.frame `df`, zal `as_tibble(df)` het in een _tibble_ veranderen. Een tibble is een speciaal soort data.frame dat gebruikt wordt door dplyr en andere pakketten van het tidyverse.[^2] Wanneer een data.frame wordt omgezet in een tibble zal de klasse veranderen.

```{r}
class(mpg)
mpg <- as_tibble(mpg)
class(mpg)
```

[^2]: ![](images/tidyverse.png) Het _tidyverse_ is een set van pakketten voor data science die in harmonie werken omdat ze gemeenschappelijke data representaties en API ontwerp delen. Het `tidyverse`-pakket is ontworpen om het gemakkelijk te maken om kernpakketten van de tidyverse te installeren en te laden met een enkel commando. De tidyverse bevat pakketten zoals: ggplot2, dplyr, tidyr, readr, purrr, tibble, hms, stringr, lubridate, forcats, jsonlite, readxl, broom, en anderen. Hadley Wickham kan beschouwd worden als de grondlegger van het tidyverse. De beste plaats om deze pakketten te leren kennen is door dit boek te lezen: [R for Data Science](http://r4ds.had.co.nz/), geschreven door Hadley en Garret Grolemund. 


Je kunt zien dat het `mpg` object nu drie verschillende `class` labels heeft. Het is nog steeds een data.frame, maar een speciaal soort data.frame, namelijk een tibble data.frame. 

Het verschil tussen een gewoon data.frame en een tibble data.frame is het meest merkbaar bij het afdrukken van (grote) data.frames. Probeer maar eens de dataset met de volgende twee regels in de console af te drukken.


```{r eval = F}
#Deze regels worden hier niet uitgevoerd 
#je kunt ze proberen in de console.
as.data.frame(mpg)
mpg
```

Merk je het verschil? Bij het afdrukken van een gewoon data.frame, zal een overvloed aan observaties worden afgedrukt in de console. Het resultaat is dat je terug naar boven moet scrollen om de variabelnamen te zien. Erger nog, wanneer de kolommen niet op een enkele pagina passen, zal elke observatie verspreid worden over verschillende lijnen, waardoor de uitvoer onleesbaar wordt. [^2a]

[^2a]: Omdat we `mpg` daarnet in een tibble data.frame hebben veranderd, kunnen we het alleen afdrukken alsof het een normaal data.frame is door de `as.data.frame` functie te gebruiken. We updaten het object echter niet, omdat we het niet opslaan met de `<-`. 




Wanneer echter een tibble data.frame wordt afgedrukt, worden standaard alleen de eerste 10 rijen afgedrukt, en variabelen die niet binnen de breedte van de pagina of console passen worden verborgen. Dit maakt de afgedrukte dataset veel leesbaarder en onze console minder rommelig. 

Het nadeel van deze aanpak is dat je soms meer waarnemingen of meer variabelen wil zien, zonder je tibble terug in een data.frame te veranderen. Je kunt dit oplossen door expliciet de `print` functie te gebruiken en de argumenten `n` en `width` in te stellen. De volgende regel drukt alle rijen en kolommen af, door beide argumenten op `Inf` te zetten, wat staat voor oneindig.[^3] Je kunt ook andere waarden gebruiken om ander aantallen kolommen en rijen te printen. Later zullen we zien hoe we specifieke rijen en kolommen kunnen printen. Merk daarnaast op dat je altijd `View()` kan gebruiken om de volledige dataset te tonen in een apart Rstudio panel. 

[^3]: Let op de hoofdletter I


```{r eval = F}
#Deze regel wordt hier niet uitgevoerd - je kunt het in de console proberen.
print(mpg, n = Inf, width = Inf)
```

Behalve voor het printen, laten tibbles enkele eenvoudiger manipulaties toe vergeleken met een normaal `data.frame` als je het pakket `tibble` installeert. Dit valt echter buiten het bereik van deze tutorial. Verder zal je zien dat de uitvoer van `dplyr` functies die in de rest van deze tutorial worden besproken automatisch tibbles zijn. Dit betekent dat je vaak niet expliciet `as_tibble` hoeft te gebruiken. Voor nu is het dus voldoende om het verschil te begrijpen.

### Glimpse

Een tweede handige functie is de `glimpse` functie. Deze functie is het `dplyr`-alternatief voor de bekende `str`-functie voor base-R, en is dus nuttig voor een eerste inspectie van de dataset die voorhanden is. Het zal een iets andere output geven dan `str`, en wordt door sommigen als netter ervaren.

```{r}
str(mpg)
glimpse(mpg)
```

### %>% 

Een andere handige functie is een heel speciale, en heet _het piping-symbool_.[^4] Het piping-symbool bestaat uit een groter-dan-teken, voorafgegaan en gevolgd door een %-teken.

Het piping-symbool kan worden gebruikt om verschillende commandos _met elkaar te verbinden_. Je kunt het vergelijken met leidingen in een waterleidingnet. Binnen een waterzuiveringsstation vervoeren leidingen het water van het ene zuiveringsstation naar het volgende en uiteindelijk naar de huishoudens. Hier gebruiken we het piping-symbool om onze gegevens van de ene manipulatie naar de volgende te brengen. Beschouw dit zeer eenvoudige voorbeeld:

[^4]: ![](images/pipe.jpg) <br/> Het piping-symbool werd voor het eerst geïntroduceerd in het pakket `magrittr`, genoemd naar de Belgische surrealistische kunstenaar René Magritte, bekend van zijn schilderij _The Threachery of Images_, oftewel _Ceci n'est pas un pipe_. 

```{r eval = F}
#Deze regel wordt hier niet uitgevoerd 
#je kunt het in de console proberen.
head(mpg)
```

We kunnen deze regel parafraseren als: "Neem het hoofd (d.w.z. de eerste 6 rijen) van de dataset `mpg`." 

Wanneer we het piping-symbool gebruiken, kan het eerste argument van een functie _voor_ de functie-aanroep worden geplaatst in plaats van erbinnen. De laatste regel code is daarom gelijk aan de volgende regel.[^brackets]

[^brackets]: Je kunt zelfs de haakjes van de functies weglaten als er geen argumenten meer zijn. Zo zou `mpg %>% head` prima werken. Verwar dit echter niet met het toevoegen van lagen aan een `ggplot` aanroep. Hier zou je de haakjes van lege functie-aanroepen moeten behouden. Voeg bijvoorbeeld niet `coord_flip` toe aan een `ggplot` object, maar voeg `coord_flip()` toe. Wees je bewust van dit verschil. Uit veiligheidsoverwegingen is het aan te raden consistent de haakjes te laten staan. 

```{r eval = F}
#Deze regel wordt hier niet uitgevoerd 
#je kunt het in de console proberen.
mpg %>% head()
```


We kunnen nu zeggen: "We nemen de dataset mpg en nemen dan het hoofd ervan." Deze zin lijkt natuurlijker, want hij is heel gemakkelijk uit te breiden met de verdere stappen die je gaat nemen.

Zoals leidingen water van de ene plaats naar de volgende brengen in een waterleidingnet, brengt het piping-symbool onze gegevens van de ene plaats naar de volgende, in dit geval de head-functie. Op dit moment lijkt het misschien belachelijk om dit te doen, maar zoals we heel snel zullen zien, komt dit symbool heel goed van pas.

Als ander voorbeeld: merk op dat de volgende twee hypothetische verklaringen zijn gelijkwaardig
```{r eval = F}
f(x,y,z)
x %>% f(y,z)
```

En als we twee functies hebben, bv. `f` en `g` die we genest hebben aangeroepen, d.w.z. de een binnen de ander, dan kunnen we het volgende doen.

```{r eval = F}
f(g(x,y),z)
# Breng het eerste argument van f naar voren
g(x,y) %>% f(z) 
# Breng het eerste argument van g naar voren
x %>% g(y) %>% f(z)
```

Dus, dit commando neemt x, voert functie g uit met argument y en dan wordt het resultaat gegeven aan functie f met tweede argument z. Dit is veel gemakkelijker te lezen dan de originele regel, waar we functie f uitvoerden op het resultaat van functie g op x en y, en z gebruikten als tweede argument voor f.

Echter, dat is genoeg wat betreft abstracte concepten. Het is tijd om iets met onze dataset te doen en dit symbool nuttig te gebruiken. 

## Univariate analyse van een continue variabele

We beginnen met een uniforme analyse van continue variabelen. Voorbeelden van continue variabelen zijn leeftijd, afstand, snelheid, gewicht, enz. Voor dit soort variabelen kunnen we het centrulm en de spreiding meten. Maatstaven voor centrum zijn gemiddelde en mediaan. Maatstaven voor spreiding zijn standaardafwijking, kwantielen, min en max, interkwartielafstand en bereik.

Al deze maatstaven hebben één ding gemeen: zij _vatten_ een continue variabele _samen_ door middel van _één_ getal, _één_ waarde. Dit kan worden uitgevoerd met behulp van de `summarise` functie van `dplyr`.[^5]

[^5]: Zowel het Brits-Engelse _summarise_ als het Amerikaans-Engelse _summarize_ kan worden gebruikt. 

Als voorbeeld, stel dat we het gemiddelde en de standaardafwijking van de `cty` willen berekenen.

```{r}
summarize(mpg, mean_cty = mean(cty), st_dev_cty = sd(cty))
```

Het eerste argument van `summarize` is het data argument. Alle volgende argumenten worden nieuwe kolommen in de resulterende tabellen. _mean_cty_ en _st_dev_cty_ zijn de namen van de nieuwe kolommen. Deze namen kan je volledig zelf beslissen. De delen na het =-teken worden de inhoud van de kolommen, d.w.z. het gemiddelde (berekend met de `mean` functie) en de standaardafwijking (berekend met de `sd` functie).

In plaats van namen zonder aanhalingstekens te geven (bijv. mean_cty), kan je ook aanhalingstekens toevoegen. Hierdoor kunt u spaties gebruiken. Wanneer je uitvoer definitief is en niet bedoeld is voor verdere manipulatie, zou u dit kunnen doen, om mooie kolomnamen te hebben in je rapport. Bijvoorbeeld`
mpg %>% summarize("Gemiddelde cty" = mean(cty))`. In het algemeen kan je spaties echter beter vermijden. 


We kunnen de bovenstaande regel herschrijven door het %>% symbool te gebruiken. Merk op dat na dit symbool, we _enter_ hebben gebruikt, zodat summarize op een nieuwe regel begint, met een inspringing. De inspringing wijst erop dat deze regels eigenlijk één statement vormen (d.w.z. de ene regel kan niet worden uitgevoerd zonder de andere).[^panderrr]

```{r}
mpg %>%
	summarize(mean_cty = mean(cty), st_dev_cty = sd(cty)) %>% 
	pander()
```

[^panderrr]: Merk op dat we ook de `pander` functie aan dit statement hebben toegevoegd. Deze functie komt uit het `pander` pakket en is afgeleid van de naam _pandoc_, een gratis, open-source software document converter. Merk op dat de resulterende tabel mooier geformatteerd is dan het resultaat van het vorige statement zonder het gebruik van `pander`. Het dient echter alleen om te gebruiken in een markdown document als opmaak belangrijk is. Het heeft geen zin te gebruiken worden bij het programmeren in de console of in r-scripts. Je kunt dit statement gewoon negeren voor de rest van deze tutorial. 




Alle functies die gebruikt worden binnen de `summarize` functie moeten *één* en slechts *één* waarde teruggeven, d.w.z. het gemiddelde, de mediaan, de interkwartielafstand, enz. We noemen deze functies _summary-functies_. Een (onvolledige) lijst van samenvattende functies is hier opgenomen:

*	`min`
*	`max`
*	`mean`
*	`median`
*	`first` (eerste element van vector)
*	`last` (laatste element van vector)
*	`n`	(aantal waarden in een dataset)[^warnings] 
*	`nth` (n-de waarde van vector)
*	`n_distinct` (aantal verschillende waarden in vecetor)
*	`IQR` (interkwartielafstand)
*	`var` (variantie)
*	`sd` (standaardafwijking)
*	`quantile`
*	`sum`

[^warnings]: WAARSCHUWING: gebruik `n` alleen binnen summarize, en telt het aantal observaties in de dataset. In tegenstelling tot alle andere functies hier neemt deze functie geen input aan. Deze functie kan dus ook niet gebruikt worden op normale vectoren, wat voor de andere functies wel geldt. 

Merk op dat (behalve `n`) al deze functies ook gebruikt kunnen worden op normale vectoren, dus niet binnen de `summarize` functie. Omgekeerd zijn dit niet de enige functies die binnen `summarize` gebruikt kunnen worden. In het algemeen kunnen alle functies die één enkele waarde teruggeven worden gebruikt. Bovendien kunnen we ook kolommen opnemen waarvan we de waarde handmatig hebben ingesteld. Bijvoorbeeld, we kunnen het laatste voorbeeld bijwerken en opnemen dat we de `cty` variabele als kolom hebben gebruikt. In dit geval hebben we geen summary-functie nodig, maar alleen een waarde, bijvoorbeeld "cty".

```{r}
mpg %>%
	summarize(variable = "cty", mean = mean(cty), st_dev = sd(cty)) %>%
	pander
```

Sommige overzichtsfuncties hebben extra argumenten nodig, zoals de `nth` functie, die een waarde voor n nodig heeft, en eventueel een ordening kan opgeven. De `quantile` functie heeft een `probs` argument nodig, dat staat voor het percentiel. Bijvoorbeeld, om het eerste 10% percentiel te berekenen, stellen we `probs = 0.1` in. Hieronder berekenen we bijvoorbeelde de kwintielen van de cty variabele. 

```{r}
mpg %>%
	summarize(variable = "cty",
			  q0.2 = quantile(cty, 0.2),
			  q0.4 = quantile(cty, 0.4),
			  q0.6 = quantile(cty, 0.6),
			  q0.8 = quantile(cty, 0.8)) %>%
	pander
```

We zien dat 20% van de _cty_ waarden kleiner is dan of gelijk is aan 13, en 20% van de _cty_ waarden groter is dan of gelijk is aan 20. In het laatste blok code hebben we elke variabele op een nieuwe regel gezet. Rstudio zal alle regels automatisch laten inspringen, zodat het duidelijk is dat het om argumenten van de `summarize` functie gaat. De pander functie komt weer op een nieuwe regel, met dezelfde inspringing als `summarize`. Geef aandacht aan je opmaak van je code, zodat deze voor anderen alsook jezelf leesbaar is. 


Als we onze resultaten willen ondersteunen met een grafiek, kunnen we een box plot of histogram plotten met `ggplot2`. Voor een introductie in ggplot2, verwijzen we naar de ggplot2 tutorial. Hieronder hebben we een histogram uitgezet. We hebben ook een verticale lijn toegevoegd om het gemiddelde van cty aan te geven, met `geom_vline`. 


```{r}
mpg %>%
	ggplot(aes(cty)) +
	geom_histogram(binwidth = 1.25, color = "black",fill = "grey") +
	geom_vline(xintercept = mean(mpg$cty), lwd = 2) +
	labs(title = "Distribution of cty",
		 x = "cty",
		 y = "Number of cars") +
	theme_minimal() +
	scale_x_continuous(breaks = seq(7.5,35,2.5))
```

Merk op hoe we ook hier het %>%-symbool gebruiken om de dataset uit de ggplot() functie te halen. In ggplot() hoeven we dan enkel nog de aesthetics te definiëren. Maar let op, na ggplot gebruik je + om nieuwe layers toe te voegen, niet %>%!

Met de summarize functie kunnen we een univariate analyse uitvoeren van de spreiding en centraliteit van elke continue variabele. Geweldig! Nu is het tijd om een stap verder te gaan en te beginnen met bivariate analyse van continue variabelen in combinatie met categorische variabelen.


##	Bivariate analysis of a continuous variable with respect to a categorical variable

Laten we, voor we met onze berekeningen beginnen, eerst grafisch verder gaan. Voordien hebben wij de verdeling van de cty geanalyseerd, zoals blijkt uit het histogram hierboven. Nu willen we deze analyseren voor verschillende soorten aandrijving (b.v. vierwielaandrijving, voorwielaandrijving of achterwielaandrijving), zoals geregistreerd door de variabele `drv`. Grafisch kunnen we verschillende histogrammen plotten voor elk van deze drie categorieën met behulp van facetten.

```{r fig.height=7}
mpg %>%
	ggplot(aes(cty)) +
	geom_histogram(binwidth = 1.25, color = "black",fill = "grey") +
	labs(title = "Distribution of cty relative to drv",
		 x = "cty",
		 y = "Number of cars") +
	theme_minimal() +
	scale_x_continuous(breaks = seq(7.5,35,2.5)) +
	facet_grid(drv~.)
```

Het is duidelijk dat er een aantal verschillen zijn tussen deze categorieën. Laten we proberen deze in cijfers uit te drukken. Wat we in feite willen doen is de centrum- en spreidingsmaten berekenen voor elk van deze categorieën, d.w.z. voor elke _groep_ van auto's. Daarom introduceren we een nieuwe dplyr-functie, genaamd `group_by`. Het eerste argument van deze functie is nodig voor de gegevens, alle andere argumenten (die normaal altijd categorisch zijn) zullen worden gebruikt om de gegevens te groeperen.



```{r}
group_by(mpg, drv)
```


De uitvoer van deze regel geeft ons gewoon een tibble, zonder opmerkelijke wijzigingen. Maar laat je niet misleiden, want die zijn er wel! Op de tweede geprinte regel lezen we "Groups: drv [3]". Deze tibble is dus gegroepeerd op de variabele _drv_, en er zijn drie verschillende groepen. Laten we, om een voorbeeld te geven, ook _trans_ als groep toevoegen.

De variabelen die je gebruikt om een dataset te groeperen zijn meestal - al zijn er uitzonderingen - categorisch. Vaak heeft het geen zin om continue variabelen te gebruiken als groep. Bijvoorbeeld, stel dat je personen groepeert op lengte, in meter. Afhankelijk van het aantal personen in je dataset, ga je maar weinig observaties per groep hebben, aangezien het gaat om een continue variabele, die heel veel waarden kan hebben. Zoals altijd zijn er uitzonderingen, zoals bv jaartallen. Het gaat dan steeds over continue variabelen waarvan het aantal verschillende waarden enigszins beperkt is - wat vaak neer komt op gehele getallen en een beperkte domein van mogelijke waarden. 


```{r}
group_by(mpg, drv, trans)
```

We kunnen gewoon _trans_ achter _drv_ zetten in de `group_by` functie. Nu kunnen we zien dat de tibble gegroepeerd is op deze twee variabelen, en er zijn 24 verschillende groepen[^groups]. We kunnen de groepering van data.frame ook controleren door de `groups` functie te gebruiken. Dit bespaart ons het afdrukken van de hele data om de groepering te controleren. Merk op dat we hieronder weer effectief gebruik maken van het piping symbool.

```{r}
mpg %>% 
	group_by(drv, trans) %>% 
	groups()
```

[^groups]: In het bijzonder zijn er 3 _drv_ waarden en 10 _trans_ waarden. Er zouden dus maximaal 30 verschillende groepen kunnen zijn. Het feit dat er slechts 24 groepen worden aangegeven, betekent dat niet alle mogelijke combinaties van _drv_ en _trans_ waarden in de gegevens voorkomen.

Oké, maar wacht eens even. Als er verder niets verandert, waarom doen we dit dan? Wel, zodra een data.frame is gegroepeerd, worden de volgende bewerkingen voor elke groep apart uitgevoerd. Is dat niet precies wat we nodig hadden? Inderdaad. Voor elke _drv_ groep, wilden we de centrum en spreidingsmaten berekenen. Laten we het eens proberen.

```{r}
mpg %>%
	group_by(drv) %>%
	summarize(mean_cty = mean(cty), sd_cty = sd(cty)) %>%
	pander()
```

Geweldig. Het gebruiken van summarize zal ons niet langer 1 rij met waarden geven. In plaats daarvan zal het 1 rij voor elke groep teruggeven. We kunnen zien dat de gemiddelde cty veel groter is voor auto's met voorwielaandrijving dan voor andere auto's, zoals reeds werd vermoed op basis van het histogram. Een andere manier om dit te visualiseren, zonder facets te gebruiken, is het gebruik van boxplots.


```{r}
mpg %>%
	ggplot(aes(drv,cty)) +
	geom_boxplot() +
	labs(title = "Distribution of cty relative to drv",
		 x = "drv",
		 y = "cty") +
	theme_minimal() +
	scale_y_continuous(breaks = seq(7.5,35,2.5)) 
```

Wij kunnen nu de centraliteit en de spreiding van een continue variabele analyseren, zowel univariaat als bivariaat, ten opzichte van een categorische variabele. Om dit te doen, hebben we geleerd om twee nieuwe functies te gebruiken: `summarize` en `group_by`. Het samenvatten van een niet gegroepeerd data.frame levert een data.frame op met 1 rij. Het samenvatten van een gegroepeerd data.frame zal een data.frame teruggeven waarvan het aantal rijen gelijk is aan het aantal groepen.

Het volgende op onze lijst is de univariate analyse van een categorische variabele. Hiervoor zullen we frequentietabellen berekenen en nog een paar nieuwe interessante functies leren: `mutate`, `arrange` en `slice`. Laten we aan de slag gaan!

\newpage

##	Univariate analyse van een categorische variabele

In onze gegevens zijn er 15 fabrikanten. Stel dat we daar meer over willen weten, d.w.z. welke fabrikant veel auto's in onze gegevens heeft, en welke minder. Grafisch kunnen we dit al doen met behulp van een staafdiagram.[^forcats] 

```{r}
mpg %>%
	ggplot() +
	geom_bar(aes(fct_infreq(manufacturer)), 
	         color = "black",fill = "grey") +
	coord_flip() +
	labs(title = "Number of cars per manufacturer",
		 x = "Manufacturer",
		 y = "Number of cars") +
	scale_y_continuous(breaks = seq(0,40,5)) +
	theme_minimal() 
```

[^forcats]: ![](images/forcats.jpg) <br/> Heb je de functie `fct_infreq` gezien die rond de _manufacturer_ variabele is gewikkeld in de geom_bar mapping?  Deze functie zorgt ervoor dat de staven worden gerangschikt van infrequent naar frequent. Deze functie is een van de handige functies voor factoren uit het pakket `forcats`, dat een anagram is van _factors_ en het symboliseert het feit dat veel mensen in de R-gemeenschap kattenliefhebbers zijn (serieus). Als je wilt, kan je het installeren en de `fct_infreq` functie gebruiken (afkorting voor "reorder this factor based on (in)frequency)". Een volledige kennismaking met dit pakket wordt (voorlopig) niet verwacht.

Nu willen we dit numeriek analyseren. De meest voor de hand liggende manier om dit te doen is met een frequentietabel. Hieronder zien we het eindproduct van deze analyse. Vervolgens zullen we deze stap voor stap gaan construeren.

```{r echo = F}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	mutate(relative_freqency = frequency/sum(frequency)) %>%
	arrange(-frequency) %>%
	mutate(cumulative_relative_frequency = cumsum(relative_freqency),
		   relative_freqency = round(relative_freqency*100, 2),
		   cumulative_relative_frequency = round(cumulative_relative_frequency*100, 2),
		   nr = row_number(-frequency)) %>%
	select(nr, everything()) %>%
	pander
```

Laten we beginnen. Het eerste wat we moeten doen is het aantal waarnemingen tellen voor elke waarde van de categorische variabele. Dus, hoeveel auto's zijn er voor elke fabrikant? We kunnen dit doen door de gegevens te groeperen op _manufacturer_ en dan het aantal rijen te tellen met `n`.

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	pander
```

De functie `n()` heeft geen enkel argument nodig. Het berekent gewoon het aantal rijen in een data.frame, of, zoals in dit geval, in elke groep. De volgende stap is om deze fabrikanten te rangschikken op basis van het aantal auto's. Om de rijen te sorteren gebruiken we de functie `arrange` van `dplyr`. Omdat we de fabrikanten willen rangschikken volgens afnemende frequentie, gebruiken we de functie `desc` (aflopend). Het volgende zal de truc doen:


```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	pander
```

Het eerste argument van `arrange` is weer de data, die aan wordt gegeven met het piping-symbool. De andere argumenten worden dan gebruikt om de gegevens te ordenen. Merk op dat meer dan één variabele kan worden opgegeven. De gegevens worden dan eerst gerangschikt met behulp van de eerste variabele. Daarna zullen de volgende variabelen worden gebruikt om ex aequo's te verbreken. Wanneer `desc` rond een variabele naam wordt geplaatst, wordt deze variabele in aflopende volgorde gerangschikt. Probeer zelf maar eens wat verschillende rangschikkingen uit!

Nu moeten we een nieuwe kolom toevoegen voor de relatieve frequenties. Hiervoor gebruiken we de functie `mutate` van `dplyr`, wat letterlijk _veranderen_ (muteren) betekent. De `mutate` functie-aanroep is vergelijkbaar met die van `summarize`: het eerste argument is de data, de andere zijn van de vorm `variabele_naam = waarde`. De variabele naam is de naam die als naam van de nieuwe kolom zal verschijnen. De waarde is de waarde voor de nieuwe kolom. Dit kan een functie zijn die een vector teruggeeft met een lengte gelijk aan die van het data.frame, of het kan een eenvoudige berekening zijn waarbij gebruik wordt gemaakt van andere variabelen in het data.frame. Het volgende statement berekent de relatieve frequenties, door elke frequentie te delen door de som van alle frequenties. 


```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency)) %>%
	pander
```

Hier verwijst `sum(frequency)` naar de som van de frequentiekolom, terwijl `frequency` verwijst naar de specifieke waarden in elke rij. Vervolgens zullen we de cumulatieve relatieve frequentie toevoegen. We kunnen dit toevoegen aan dezelfde `mutate` aanroep. 

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency),
		   relative_cumulative_frequency = cumsum(relative_frequency)) %>%
	pander
```

Terwijl de berekening van de relatieve frequentie een eenvoudige formule was, wordt de cumulatieve frequentie berekend met behulp van de `cumsum`. Dit is wat men noemt een _windowfunctie_. Terwijl summary-functies altijd één waarde teruggeven, geven windowfuncties hetzelfde aantal waarden terug als de vector die als invoer wordt gebruikt. Dus, onze 15 relatieve frequenties zullen resulteren in 15 cumulatieve frequenties. Andere windowfuncties worden hieronder opgesomd. 


**Cumulative functions**

* cumsum: De cumulatieve som van een vector
* cummax: Het cumulatieve maximum van een vector
* cummin: Het cumulatieve minimum van een vector
* cumprod: Het cumulatieve product van een vector
* cummean: Een cumulatief, of voortschrijdend, gemiddelde 
* cumany: Voor logische waarden, een cumulatieve "of"
* cumall: Voor logische waarden, een cumulatief "en"
* cume_dist: Cumulatieve verdeling

**Element-wise function of more than one variable**

* pmax: Element/paar-gewijs maximum van een vector
* pmin: Element/paar-gewijs minimum van een vector

**Ranking function**

* percent_rank: rangen geschaald naar [0,1]
* row_number: Rang die banden breekt door elementen te nemen door eerste voorkomen (meestal alfabetisch)
* min_rank: Rang die groepen breekt door ze dezelfde rang te geven en de volgende rang weg te laten
* dense_rank: Zelfde als min_rank, maar zonder weglating

**Shifting functions**

* lead(n): verschuif waarden n plaatsen naar voren, voeg n NA's toe als laatste waarden
* lag(n): verschuif waarden n plaatsen naar achteren, voeg n NA's toe als eerste waarden

**Other**

* between(a,b): Liggen de waarden van een vector tussen a en b? Geeft logisch
* ntile(x,n): Gebruik variabele x om de waarnemingen te rangschikken en ze in n even grote groepen te plaatsen. 

Dat is een lange lijst, en ze zijn niet allemaal belangrijk. Sommige zul je veel gebruiken (zoals cumsum), en andere alleen in zeldzame gevallen (of nooit). In geval van nood, kom dan terug naar deze lijst. 

De `pmin` functie geeft het paarsgewijze minimum van x en y, terwijl de `pmax` functie het paarsgewijze maximum van x en y geeft. Hoewel de p in deze functies wijst naar _paar_ kan het gebruikt worden op meer dan twee vectoren. Ze verschillen van `min` en `max` aangezien deze laatste sumaary functies werken, die op basis van een getal het minimum/maximum teruggeven. 

Een voorbeeld: 

Beschouw de vectoren x en y met 10 willekeurige waarden
```{r}
x <- runif(10)
y <- runif(10)
x
y
```
Gebruik van summary-functies
```{r}
min(x)
min(y)
max(x)
max(y)
```

Gebruik van de pair-wise window functies. 

```{r}
pmin(x,y)
pmax(x,y)
```
Merk op dat max(x,y) het maximum geeft uit beide vectors, waar pmax(x,y) het maximum geeft op elke positie in de vectoren. 

```{r}
max(x,y)
```

```{r}
data.frame(x = sample(1:10)) %>%
	mutate(lead = lead(x),
		   lag = lag(x,2),
		   between(x,4,8),
		   ntile(x,5)) %>%
	pander
```

Een voorbeeld van de vensterfuncties lead, lag, between en ntile wordt hierboven getoond. De lead en lag functies verschuiven waarden naar boven en beneden. Standaard worden ze met één plaats verschoven. De between functie test of waarden tussen bepaalde grenzen liggen (inclusief de grenswaarden). Tenslotte creëert de ntile-functie een variabele die waarnemingen groepeert in gelijke bins, in dit geval 5, volgens een bepaalde variabele. Zo worden waarden 1 en 2 van x gegroepeerd in bin 1, waarden 3 en 4 in bin 2, enz. Merk op dat, hoewel de ntile functie getallen teruggeeft, het eigenlijk een categorische variabele is!

Ze zien er misschien niet allemaal even logisch uit, maar soms kunnen deze windowfuncties heel krachtig en handig zijn tijdens een analyse. Zorg ervoor dat je hun bestaan kent. Maar, laten we nu teruggaan naar onze frequentietabel, want we zijn een beetje van het gebaande pad afgeraakt. Hieronder tonen we nogmaals ons laatste resultaat.

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency),
		   relative_cumulative_frequency = cumsum(relative_frequency)) %>%
	pander
```

We waren al klaar, zo lijkt het, maar we kunnen de tabel nog verbeteren. Een manier om dat te doen is om de relatieve (cumulatieve) frequenties om te zetten in waarden tussen 0 en 100, en om ze af te ronden op 2 decimalen. Dat laatste kan met de functie `round` en met opgave van het aantal decimalen.

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency),
		   relative_cumulative_frequency = cumsum(relative_frequency),
		   relative_frequency = round(100*relative_frequency,2),
		   relative_cumulative_frequency = round(100*relative_cumulative_frequency,2)) %>%
	pander
```

Wat hier belangrijk is om op te merken, is dat we 4 verschillende statements in mutate hebben gezet. In deze statements is het mogelijk om variabelen te gebruiken die eerder __binnen dezelfde mutate call__ zijn aangemaakt: het tweede statement gebruikt de variabele in het eerste. Ook is het mogelijk om variabelen te overschrijven, d.w.z. statement 3 en 4 overschrijven de variabelen aangemaakt in statement 1 en 2.

Je vraag je misschien af waarom we 4 opgaven gebruiken in plaats van 2, en waarom we niet onmiddellijk hebben afgerond? Dat hadden we kunnen doen voor de cumulatieve frequentie, maar niet voor de relatieve frequentie. Kan je achterhalen waarom?

Tenslotte willen we soms een rangorde, d.w.z. een rijnummer, toevoegen aan de frequentietabel. Hier gebruiken we de `row_number` functie die we hierboven hebben geïntroduceerd.



```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency),
		   relative_cumulative_frequency = cumsum(relative_frequency),
		   relative_frequency = round(100*relative_frequency,2),
		   relative_cumulative_frequency = round(100*relative_cumulative_frequency,2),
		   nr = row_number(-frequency)) %>%
	pander(split.table = 120)
```

Eerder gebruikten we `desc` om aflopend te rangschikken in `arrange`, en nu gebruiken we het minteken om de rijnummers toe te wijzen volgens afnemende frequentie. Is `dplyr` echt zo inconsistent? Gelukkig is het antwoord nee. Het gebruik van het minteken is een trucje om je code te verkorten, maar kan alleen gebruikt worden voor numerieke variabelen. Dit komt omdat het afnemend sorteren van een numerieke variabele hetzelfde is als het toenemend sorteren van zijn negatieve spiegelbeeld (Overtuig jezelf!). Als zodanig, hadden we ook het minteken kunnen gebruiken binnen arrange, en we hadden `desc` kunnen gebruiken binnen row_number. **Maar**, gebruik nooit het minteken om categorische waarden te sorteren (ze hebben geen negatieve tegenhanger, typisch). Het is best practice om consistent te zijn in het gebruik van - of `desc`, maar omdat dit een tutorial is, laten we je verschillende manieren zien om het te doen.

Mutate heeft het nummer aan het eind van de tabel toegevoegd. Dat is wat we in de meeste gevallen willen, maar niet in dit geval. Om de volgorde van de variabelen te veranderen, kunnen we de `select` functie van `dplyr` gebruiken. Deze functie kan worden gebruikt om variabelen te _selecteren_, en zal ze in de opgegeven volgorde plaatsen. Dus, wat we kunnen doen is het volgende.

[^pandersplit]: Voor de leergierige studenten die zich afvroegen waar het `split.table = 120` argument vandaan kwam in de `pander` aanroep: `pander` splitst standaard tabellen die meer dan 80 tekens breed zijn. Het zal dan overbodige kolommen onder de tabel toevoegen in een _tweede_ tabel. Om dit splitsen te voorkomen, en omdat dit document een vrij grote zijmarge heeft om de tabel door te laten lopen, heb ik deze parameter verhoogd naar 120 tekens. Verder is dit niet relevant voor onze analyse. 

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency),
		   relative_cumulative_frequency = cumsum(relative_frequency),
		   relative_frequency = round(100*relative_frequency,2),
		   relative_cumulative_frequency = round(100*relative_cumulative_frequency,2),
		   nr = row_number(-frequency)) %>%
	select(nr, manufacturer, frequency, relative_frequency, relative_cumulative_frequency) %>%
	pander(split.table = 120)
```


Het gebruik van het `select` statement doet de truc. Maar ik ben nog steeds een beetje lui, en ik wil niet alle variabelen uitschrijven, alleen maar om er één op de eerste positie te zetten. We hadden hier maar 5 variabelen, maar stel je voor wat een verspilling van tijd het zou zijn als we er meer hadden, zoals 6 bijvoorbeeld. Kunnen we niet gewoon zeggen, zet _nr_ vooraan, en voeg dan alle andere variabelen toe in hun oorspronkelijke volgorde? Dplyr biedt redding!

Gelukkig kunnen we dat. We kunnen gewoon de functie `everything` toevoegen aan select. Dit zal alle kolommen na _nr_ toevoegen, zonder _nr_ voor een tweede keer te herhalen. Geweldig, is het niet?

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency),
		   relative_cumulative_frequency = cumsum(relative_frequency),
		   relative_frequency = round(100*relative_frequency,2),
		   relative_cumulative_frequency = round(100*relative_cumulative_frequency,2),
		   nr = row_number(-frequency)) %>%
	select(nr, everything()) %>%
	pander(split.table = 120)
```


Select, arrange, mutate, summary, group_by. We hebben dplyr al aardig onder de knie. Toch niet zo moeilijk, is het niet? Natuurlijk zijn er nog meer functies, maar deze 5 behoren echt tot de belangrijkste functies voor data manipulatie. Alleen `filter` ontbreekt in de dplyr hall of fame, maar die laten we voor een andere keer. Het is altijd een goed idee om iets te hebben om naar uit te kijken, vind je niet?

Voordat we verder gaan met bivariate analyse, zijn er nog twee dingen die we moeten doen. Kijk naar de `slice` functie, en nog eens terugkijken naar het %>% symbool. 

De `slice` functie kan gebruikt worden om rijen uit een data.frame te `slicen`. Stel dat we een hele lange frequentietabel hebben, en we zijn alleen geïnteresseerd in de top 10 waarden. We kunnen dan de eerste 10 rijen van deze tabel als volgt slicen.

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	arrange(desc(frequency)) %>%
	mutate(relative_frequency = frequency/sum(frequency),
		   relative_cumulative_frequency = cumsum(relative_frequency),
		   relative_frequency = round(100*relative_frequency,2),
		   relative_cumulative_frequency = round(100*relative_cumulative_frequency,2),
		   nr = row_number(-frequency)) %>%
	select(nr, everything()) %>%
	slice(1:10) %>%
	pander(split.table = 120)
```

Dat is slice. Niets meer, niets minder. We hebben een _groot_ blok code opgebouwd, maar ons pipingsymbool rijgt het netjes aan elkaar, nietwaar? Stel je even voor dat we dit symbool niet hadden. In zo'n geval zouden we elk eerste argument opnieuw moeten plaatsen in de functie waar het door wordt gevolgd. Dus, mpg moet in group by. De group_by zou in summarize moeten staan, enz. Het resultaat zou het volgende zijn.

```{r eval = F}
pander(
	slice(
		select(
			mutate(
				arrange(
					summarize(
						group_by(mpg, 
								 manufacturer), 
						frequency = n()), 
					desc(frequency)),
				relative_frequency = frequency/sum(frequency),
				relative_cumulative_frequency = cumsum(relative_frequency),
				relative_frequency = round(100*relative_frequency,2),
		 		relative_cumulative_frequency = round(100*relative_cumulative_frequency,2),
				nr = row_number(-frequency)), 
			nr, 
			everything()), 
		1:10)
	)

```

Dat is nogal een puinhoop, is het niet? Alle functies zijn gescheiden van hun argumenten, en we kunnen niet echt opmaken wat we aan het doen waren. Het piping symbool doet zijn werk om onze code leesbaar en begrijpelijk te maken. Zorg ervoor dat je het verstandig gebruikt!

Nu gaan we verder met de bivariate analyse van twee continue variabelen.

## Bivariate analyse van een continue variabele ten opzichte van een andere continue variabele

De relatie tussen twee continue variabelen kan gemakkelijk grafisch worden weergegeven met een scatter plot. Laten we eens kijken naar _cty_ ten opzichte van _hwy_. 

```{r}
mpg %>%
	ggplot(aes(cty, hwy)) +
	geom_point() +
	theme_minimal() +
	labs(title = "Relationship between hwy and cty")
```

Er is een zeer duidelijk verband tussen deze variabelen, en het blijkt vrij lineair te zijn. Laten we een lineaire lijn trekken door de puntenwolk. 

```{r}
mpg %>%
	ggplot(aes(cty, hwy)) +
	geom_point() +
	theme_minimal() +
	labs(title = "Relationship between hwy and cty") +
	geom_smooth(method = "lm", se = F)
```

Een lineair verband als dit kan zeer effectief worden gemeten met de correlatiecoëfficiënt. Het berekenen van correlaties kan worden gedaan met de base-R functie `cor`. Deze functie verwacht echter een data.frame met alleen continue variabelen, omdat het alle mogelijke correlaties tussen deze zal berekenen. Correlaties tussen categorische variabelen (behalve ordinale) kunnen niet worden berekend. Daarom selecteren we eerst de continue variabelen met de `select` functie van `dplyr`. De variabelen waarin we geïnteresseerd zijn, zijn _displ, year, cty_ en _hwy_.

```{r}
mpg %>%
	select(displ, year, cty, hwy) %>% 
	cor %>% 
	pander
```


De `select` aanroep kan groot worden bij het selecteren van numerieke variabelen in een grote dataset. We kunnen het herschrijven met de `select_if` functie, die geen variabele namen verwacht, maar wel een functie nodig heeft om te testen of een variabele meegenomen moet worden of niet. We kunnen de `is.numeric` functie gebruiken om te testen of een vector numeriek is. Dus, [^selectif]

[^selectif]: Merk op hoe we de `is.numeric` functie binnen select_if gebruiken: zonder aanhalingstekens en zonder haakjes. Dit is belangrijk!

```{r}
mpg %>% select_if(is.numeric) %>%
	cor %>%
	pander
```

Hier zien we de zeer sterke correlatie tussen cty en hwy. Wij zien ook sterke negatieve correlaties tussen _displ_ enerzijds en _cty_ en _hwy_ anderzijds. Kan je proberen deze te visualiseren zoals wij hebben gedaan voor _cty_ en _hwy_?

We zouden ook de door `cor` berekende correlaties kunnen visualiseren met ggplot, maar er is iets mis. De gegevens die de correlatiefunctie oplevert zijn niet erg netjes. Er zijn variabele namen in de kolommen en in de rijen? Nog erger, het is geen data.frame!

```{r}
mpg %>% 
	select_if(is.numeric) %>%
	cor %>% 
	class
```

Matrix? De film? Nee, matrix is een ander type object in R waar je misschien nog niet van gehoord hebt. Terwijl een data.frame een verzameling vectoren is, kun je een matrix zien als een tweedimensionale vector. Dit betekent dat, net als in een vector, alle elementen in een matrix hetzelfde type moeten hebben. Zoals een vector namen kan hebben, kunnen ook de rijen en kolommen van een matrix namen hebben, zoals in ons voorbeeld.


Maar, zoals we weten, kan `ggplot2` alleen werken met data.frames. We zijn compleet verloren! Maar, we kunnen misschien van een matrix een data.frame maken. En dan kunnen we het zo aanpassen dat alle variabelen in kolommen staan. We kunnen het proberen...

Maar, dat lijkt een hoop werk. En we zijn nog steeds lui. Gelukkig zijn de meeste R-gebruikers tot op zekere hoogte lui, en iemand moet dit werk ooit gedaan hebben, en moet zo genereus geweest zijn om het in een pakket te stoppen. `ggcorrplot` is het antwoord. Het `ggcorrplot` pakket heeft één enkele functie die nuttig is voor ons: `ggcorrplot`. Merk op dat zowel het pakket als de functie dezelfde naam hebben gekregen. Hoe genereus! Maar wees voorzichtig: `cor` had één r, `ggcorrplot` heeft er twee.

```{r}
library(ggcorrplot)
```


```{r}
mpg %>%
	select_if(is.numeric) %>%
	cor %>% 
	ggcorrplot()
```

Wat we krijgen is een visuele matrix. De kleur van de vierkantjes geeft de richting van het verband aan (standaard is rood positief en blauw negatief). Er zijn echter veel verschillende opties om `ggcorrplot` te maken zoals we het willen. Laten we eens kijken naar de belangrijkste:

* method: "square" of "circle": de vorm van de elementen in de matrix
* lab: indien TRUE, zullen de correlatiewaarden boven de vierkanten (of cirkels) worden getoond
* lab_col en lab_size: hiermee kunnen we veranderen hoe de waarden worden afgedrukt
* outline_color: de kleur van de randen van de vierkanten
* type: "full", "lower" of "upper": een correlatiematrix is symmetrisch, dus we kunnen kiezen om alleen de onderste of de bovenste helft te tonen.
* ggtheme: je kan één van de standaard ggplot2-thema's gebruiken: theme_grey, theme_minimal, theme_classic. Geef ze op zonder haakjes of aanhalingstekens, net zoals we een paar minuten geleden deden met `is.numeric`.
* titel
* legende.titel
* colors, een vector van drie kleuren voor de lage, midden en hoge waarden. Standaard: c("blauw", "wit", "rood")
* hc.order: indien ingesteld op TRUE kunnen we de variabelen ordenen om te tonen welke variabelen het meest verwant zijn
* show.diag: Toon de diagonaal indien TRUE (in geval type gelijk is aan "lower" of "upper")

An example of a slightly modified version of our plot is the following: [^corrplot]

```{r}
mpg %>%
	select_if(is.numeric) %>%
	cor %>% 
	ggcorrplot(type = "lower", ggtheme = theme_minimal, colors = c("#6D9EC1","white","#E46726"),
			   show.diag = T,
			   lab = T, lab_size = 5,
			   title = "Correlation Matrix for the mpg dataset",
			   legend.title = "Correlation Value",
			   outline.color = "white",
			   hc.order = T)
```

[^corrplot]: Meer informatie en instellingen voor deze plots zijn te vinden in [deze handleiding](https://github.com/kassambara/ggcorrplot)


We hebben al een lange en opwindende weg afgelegd door het tidyverse! Het laatste wat we willen kunnen, is een bivariate analyse doen van twee categorische variabelen. Hiervoor zullen we contingentietabellen leren construeren. We hebben bijna alle soorten beschrijvende analyse onder de knie. 

##	Bivariate analyse van een categorische variabele ten opzichte van een andere categorische variabele

We beginnen weer met het bekijken van een grafiek. Stel dat we de relatie tussen _class_ en _cyl_ willen bekijken. We zouden facetted staafdiagrammen kunnen maken.

```{r}
mpg %>%
	ggplot(aes(class)) +
	geom_bar() +
	facet_grid(~cyl) +
	coord_flip()
```

Hier zien we dat de verdeling van de class verschilt wanneer het aantal cilinders verandert. Voor 4 cilinders zijn de meeste auto's compact, terwijl voor 8 cilinders de meeste auto's suv's zijn. We kunnen het echter ook vanuit een ander perspectief bekijken.

```{r}
mpg %>%
	ggplot(aes(cyl)) +
	geom_bar() +
	facet_grid(~class)
```

En nog een

```{r}
mpg %>%
	ggplot(aes(cyl)) +
	geom_bar(aes(fill = class))
```

En nog een

```{r}
mpg %>% 
	ggplot(aes(class)) +
	geom_bar(aes(fill = cyl))
```

En nog een

```{r}
mpg %>% 
	ggplot(aes(class)) +
	geom_bar(aes(fill = cyl), position = "fill")
```

Er zijn inderdaad vele manieren om de relatie tussen twee categorische variabelen te bekijken. De vele grafieken die kunnen worden gemaakt, geven aan dat er ook meerdere contingentietabellen kunnen zijn. Alles hangt echt af van de vraag die je wilt beantwoorden. Gelukkig kennen we inmiddels al een heleboel belangrijke functies, die we goed kunnen gebruiken. We beginnen met te tellen hoeveel auto's er zijn voor elke cilinder-klasse combinatie.

```{r}
mpg %>%
	group_by(cyl, class) %>%
	summarize(frequency = n()) %>% 
	pander
```

Geweldig, dat ging perfect! Om hier een contingentietabel van te maken, willen we een van de twee variabelen op de kolommen zetten. Dit zal een matrix-achtige structuur creëren. Hier hebben we een nieuwe functie voor nodig, die `spread` heet. Deze functie komt uit het `tidyr` pakket, dat wordt gebruikt om gegevens op te schonen. Echter, de andere functies uit dit pakket zullen hier niet worden besproken. 

De functie spread heeft 2 argumenten, `key` en `value` (behalve data, natuurlijk). De key verwijst naar de variabele waarvan we de waarden als nieuwe kolommen willen plaatsen, in dit geval _class_. De value verwijst naar de variabele waarvan we de waarden in de nieuwe kolommen willen plaatsen, in dit geval onze frequentie. Geen idee wat er gaat gebeuren? Laten we eens naar een voorbeeld kijken.

```{r}
mpg %>%
	group_by(cyl, class) %>%
	summarize(frequency = n()) %>% 
	spread(class, frequency) %>%
	pander
	
```

Heb je gezien wat er gebeurd is? Vergelijk gewoon de laatste twee tabellen. Wat gebeurt er als je cyl als key gebruikt?

Nu, waarom tonen sommige van de waarden in dit data.frame NA, wat staat voor Not Available? Dat komt omdat niet alle class-cyl combinaties bestaan, d.w.z., onze lijst voordien toonde ons slechts 19 bestaande combinaties. Er zijn geen auto's voor de andere 9 combinaties. We houden echter niet zo van NA's, dus laten we ze veranderen in nullen. Gelukkig is dit een functie van de `spread` functie. Het argument `fill` wordt gebruikt om de lege cellen te "vullen". We hoeven het alleen maar op nul te zetten. [^fill]

[^fill]: We zijn fill al in verschillende contexten tegengekomen. Het wordt gebruikt om de vulkleur in plots te specificeren, het kan gebruikt worden als een position in geom_bar om de balken tot 100% te vullen, en nu kunnen we het gebruiken om lege ruimtes in de contingentietabel op te vullen. Verwar ze niet met elkaar!

```{r}
mpg %>%
	group_by(cyl, class) %>%
	summarize(frequency = n()) %>% 
	spread(class, frequency, fill = 0) %>%
	pander
	
```


Geweldig. Dit is wat ik zou noemen een "Contingentietabel met absolute frequenties". Het toont ons het absolute aantal auto's voor elke combinatie van cilinder en klasse, en het vertelt ons dat de combinatie 8 cilinders en SUV het meest prominent is in onze gegevens. Deze contingentietabel past heel goed bij onze eerste twee grafieken.

Een andere vraag die we kunnen stellen is: Als we kijken naar auto's met 4 cilinders, wat is dan de specifieke verdeling over de klassen? In dit geval zouden we relatieve frequenties willen hebben. Laten we dit eens proberen. 

```{r}
mpg %>%
	group_by(cyl, class) %>%
	summarize(frequency = n()) %>% 
	mutate(relative_frequency = frequency/sum(frequency)) %>%
	pander
```


Dat is precies wat we wilden hebben. Maar, valt je niet iets vreemds op? 

Binnen elke cilindergroep tellen de relatieve frequenties op tot één. Kijk bijvoorbeeld naar cyl = 5, daar zijn 50% compacte auto's en 50% subcompact. Dat is wat we wilden, maar... dit is niet wat er eerder gebeurde bij het maken van frequentie tabellen. Wat is er veranderd?

Het antwoord is subtiel, lastig en belangrijk.

Telkens wanneer een sommatie wordt gedaan van een gegroepeerd data.frame, verwijdert summary de laatste groeperingsvariabele. In het geval van onze frequentietabel eerder:

```{r}
mpg %>%
	group_by(manufacturer) %>%
	summarize(frequency = n()) %>%
	groups
```

Na het samenvatten, zijn er geen groeperingsvariabelen meer. Er was er maar één, en die is verwijderd. De functie summarize gaat er impliciet van uit dat de groepering nutteloos is geworden na de summarize. Dit betekent dat, als we `sum(frequency)` in de volgende regel gebruiken om relatieve frequenties te berekenen, het de som van de frequenties in de hele tabel zou berekenen.

Nu, terug naar ons voorbeeld. Nadat de frequenties zijn berekend, zijn de gegevens alleen gegroepeerd per cyl. Dus `sum(frequency)` berekent nu de som van de frequenties voor elke cyl-groep. Inderdaad, vergeet niet, voor een gegroepeerd data.frame, gebeuren alle bewerkingen afzonderlijk voor elke groep. Dat is precies de reden waarom de relatieve frequenties binnen elke cyl-groep bij 1 optellen. 


```{r}
mpg %>%
	group_by(cyl, class) %>%
	summarize(frequency = n()) %>%
	groups
```

Als we de volgorde van de groeperingsniveaus in de `group_by` functie veranderen, veranderen we ook de relatieve frequenties die berekend zullen worden. Als we de klasse eerst zetten, zullen de relatieve frequenties voor elk van de klassen opgeteld 1 zijn.

```{r}
mpg %>%
	group_by(class, cyl) %>%
	summarize(frequency = n()) %>%
	mutate(relative_frequency = frequency/sum(frequency)) %>%
	pander

```


Toegegeven, dit is verwarrend, maar tegelijkertijd is het zeer nuttig. Je moet dus wel letten op de volgorde van de variabelen in de group_by functie, en op het aantal samenvattingen dat na het groeperen wordt gebruikt.

Nu we de relatieve frequenties hebben, kunnen we die met `spread` opnieuw vormgeven om een matrix-achtige tabel te maken. Deze keer stellen we de relatieve_frequentie in als waarde.

```{r}
mpg %>%
	group_by(class, cyl) %>%
	summarize(frequency = n()) %>%
	mutate(relative_frequency = frequency/sum(frequency)) %>%
	spread(cyl, relative_frequency, fill = 0)	%>%
	pander
```

Oh... dat is niet wat we verwacht hadden? We verwachtten één rij voor elke klasse, maar nu hebben we er meer dan één. De reden is eenvoudig. Voor elke combinatie van klasse en cilinder hebben wij twee waarden: frequentie en relatieve frequentie. Wanneer wij de relatieve frequenties over één lijn willen verdelen, is er geen plaats meer voor de frequenties. Het gevolg is dat de lijnen niet meer, zoals voorheen, tot één lijn kunnen _samenvallen_. We kunnen dit echter eenvoudig oplossen door eerst de frequenties weg te nemen, door select te gebruiken. 

```{r}
mpg %>%
	group_by(class, cyl) %>%
	summarize(frequency = n()) %>%
	mutate(relative_frequency = frequency/sum(frequency)) %>%
	select(-frequency) %>%
	spread(cyl, relative_frequency, fill = 0) %>% 
	pander
```

Dit lijkt er meer op. Merk op dat in plaats van de variabelen die we willen houden aan te geven met select, we de variabele die we willen verwijderen aangeven met een minteken, wat veel korter is. Verwar het niet met het minteken bij het rangschikken van gegevens, want dat is iets heel anders.

Op elke rij kunnen we nu de verdeling van verschillende cilinders zien voor een bepaalde klasse auto's. Je zou het ook andersom kunnen draaien, en de verdeling van verschillende klassen voor een specifiek aantal cilinders kunnen laten zien. Net zoals we vele grafieken hadden om naar deze twee variabelen te kijken, kunnen we vele contingentietabellen maken. 

Stel ten slotte dat we een contingentietabel willen met algemene relatieve frequenties. D.w.z. dat we de vraag willen beantwoorden: welk percentage van de auto's heeft 5 cilinders en is van de klasse compact. We kunnen het laatste stukje code recyclen, en we hoeven maar één regel toe te voegen.

```{r}
mpg %>%
	group_by(class, cyl) %>%
	summarize(frequency = n()) %>%
	ungroup() %>%
	mutate(relative_frequency = frequency/sum(frequency)) %>%
	select(-frequency) %>%
	spread(cyl, relative_frequency, fill = 0) %>% 
	pander
```

De functie ungroup die we hebben toegevoegd, verwijdert alle groepen. Als gevolg daarvan wordt de som van de frequenties berekend over het volledige data.frame. Dus, alleen de relatieve frequenties van alle combinaties zullen bij elkaar opgeteld één zijn (je kan het zelf narekenen).

## Background material

Wij hebben 5 verschillende analyses uitgevoerd en onderweg heel wat nieuwe nuttige functies geleerd. Vergeet zeker niet de belangrijkste: select, arrange, group_by, summarize, mutate en spread! 

Als je meer wilt weren, kan je deze materialen raadplegen:

*	[R for Data Science](http://r4ds.had.co.nz/), chapter 5
*	[dplyr Introduction](https://cran.rstudio.com/web/packages/dplyr/vignettes/dplyr.html)



